{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6ce85f8-d5d9-4703-a18b-03007d52f7df",
   "metadata": {},
   "source": [
    "# WORDLE Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3c5980e-26cb-449e-8783-bf62f77d7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from scipy.stats import entropy\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da5f6c63-45b7-4479-8a22-7cc83d5d7bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_FILES = [\"data/wordle-guesses.txt\", \"data/wordle-answers.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "322e6060-a87c-4d4b-a7cf-8c111524fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(filepaths):\n",
    "    vocab = set()\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath) as f:\n",
    "            for line in f:\n",
    "                vocab.add(line.strip())\n",
    "            \n",
    "    vocab_list = list(vocab)\n",
    "    vocab_to_idx = {w:i for i, w in enumerate(vocab_list)}\n",
    "    return vocab_list, vocab_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "52f259e7-cfa8-4261-b69a-290f95ccfc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12972\n"
     ]
    }
   ],
   "source": [
    "vocab_list, vocab_to_idx = load_vocab(VOCAB_FILES)\n",
    "print(len(vocab_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c9ced-2b25-4d44-83bd-fba1a982fc58",
   "metadata": {},
   "source": [
    "## Hint Representation\n",
    "\n",
    "We need a function that produces the hint string given a guess word and a goal word.\n",
    "\n",
    "Hints take the form of an n-length array where n is the length of the guess word. Hints are created with the following rules (Let $c_i$ be the $i$th character of the guess word):\n",
    "\n",
    "1. The $i$th position in the hint contains a 0 if $c_i$ does not appear in the goal word or if the $i$-length prefix of the guess word contains at least $n$ instances of $c_i$, where $n$ is the number of times $c_i$ appears in the goal word.\n",
    "\n",
    "2. The $i$th position in the hint contains a 1 if $c_i$ appears in the goal word, but not in position $i$. \n",
    "\n",
    "3. The $i$th position in the hint contains a 2 if the $i$th position of the goal word is $c_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c70ecab-88a9-495b-9120-8bb60b55bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hint(guess_word, goal_word):\n",
    "    hint = np.zeros(len(guess_word), dtype=int)\n",
    "    \n",
    "    guess_counts = defaultdict(int)\n",
    "    goal_counts = Counter(goal_word)\n",
    "    \n",
    "    for i, c in enumerate(guess_word):\n",
    "        guess_counts[c] += 1\n",
    "        \n",
    "        if goal_counts[c] < guess_counts[c]:\n",
    "            hint[i] = 0\n",
    "            continue\n",
    "        \n",
    "        if c != goal_word[i]:\n",
    "            hint[i] = 1\n",
    "            continue\n",
    "            \n",
    "        hint[i] = 2\n",
    "        \n",
    "    return hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e681fb5-5553-4c1a-b019-7e60ef877b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_hint = get_hint(\"aroma\", \"alter\")\n",
    "example_hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf717ad0-1ad1-4391-ab30-8eb00b298487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hint_to_str(hint):\n",
    "    chars = [\"_\", \"o\", \"x\"]\n",
    "    hint_str = \"\".join([chars[idx] for idx in hint])\n",
    "    return hint_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e1ea393c-740a-4606-bee6-67eda2ebbef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_hint(hint_str):\n",
    "    d = {'_':0, 'o':1, 'x':2}\n",
    "    hint = np.zeros(len(hint_str), dtype=int)\n",
    "    for i, c in enumerate(hint_str):\n",
    "        hint[i] = d[c]\n",
    "    return hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4019ed49-6da3-4563-b926-37ede464ac96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xo___'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hint_str = hint_to_str(example_hint)\n",
    "hint_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd3d4db9-96f7-4c90-a67f-569cda588ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_to_hint(hint_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6514667-77e2-40a7-9f24-7b6ecf224e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hint_to_num(hint, base=3):\n",
    "    hint_num = 0\n",
    "    factor = 1\n",
    "    for i, v in enumerate(hint):\n",
    "        hint_num += v * factor\n",
    "        factor *= base\n",
    "    return hint_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3ab0e59-46a3-4397-be51-2cad51616e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_hint(hint_num, base=3, sz=5):\n",
    "    hint = np.zeros(sz, dtype=int)\n",
    "    factor = base**(sz-1)\n",
    "    for i in range(sz-1, -1, -1):\n",
    "        digit = 0\n",
    "        while (hint_num >= digit * factor) and (digit < base): \n",
    "            digit += 1\n",
    "        hint[i] = digit - 1\n",
    "        hint_num -= (digit - 1) * factor\n",
    "        factor /= base\n",
    "    return hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2b88917f-c405-4980-8c66-eaa830f4566d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hint_num = hint_to_num(example_hint)\n",
    "hint_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5402f903-87b3-4b87-b750-f902acd077f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_to_hint(hint_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd23351-d53b-4f30-9a6c-fc03dbcb3cc9",
   "metadata": {},
   "source": [
    "Since constructing the hint for a particular word combination can become costly when done repeatitively, it is faster to pre-load a \"hint-matrix\" that stores the results of evaluating all possible guess and goal word combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f97ff576-d46d-41c4-b14c-d6ee5d1b9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hint_matrix(vocab_list=None, load=None, save=None):\n",
    "    \n",
    "    if load is not None:\n",
    "        hint_matrix = np.load(load)\n",
    "    \n",
    "    else:\n",
    "        n_words = len(vocab_list)\n",
    "        hint_matrix = np.zeros((n_words, n_words), dtype=int)\n",
    "\n",
    "        hint_dict = {}        \n",
    "        for i, guess_word in tqdm_notebook(enumerate(vocab_list), total=n_words):\n",
    "            for j, goal_word in enumerate(vocab_list):\n",
    "                hint = get_hint(guess_word, goal_word)\n",
    "                hint_bytes = hint.tobytes()\n",
    "                if hint_bytes not in hint_dict:\n",
    "                    hint_dict[hint_bytes] = hint_to_num(hint)\n",
    "                hint_matrix[i,j] = hint_dict[hint_bytes]\n",
    "    \n",
    "    if save is not None:\n",
    "        np.save(save, hint_matrix)\n",
    "    \n",
    "    return hint_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8557702-4684-403c-9ef5-26595b28c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hint_matrix_fast(vocab_list, n_threads=2):\n",
    "    n_words = len(vocab_list)\n",
    "    hint_matrix = np.zeros((n_words, n_words), dtype=int)\n",
    "    \n",
    "    hint_dict = {}\n",
    "    def fill_rows(start, end):\n",
    "        for i, guess_word in tqdm_notebook(enumerate(vocab_list[start:end]), total=end-start):\n",
    "            for j, goal_word in enumerate(vocab_list):\n",
    "                hint = get_hint(guess_word, goal_word)\n",
    "                hint_bytes = hint.tobytes()\n",
    "                if hint_bytes not in hint_dict:\n",
    "                    hint_dict[hint_bytes] = hint_to_num(hint)\n",
    "                hint_matrix[start + i,j] = hint_dict[hint_bytes]\n",
    "                \n",
    "    section_sz = int(n_words / n_threads) + 1\n",
    "    threads = []\n",
    "    for start in range(0, n_words, section_sz):\n",
    "        end = start + section_sz if start + section_sz < n_words else n_words\n",
    "        t = threading.Thread(target=fill_rows, args=(start, end))\n",
    "        t.start()\n",
    "        \n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    \n",
    "    return hint_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88ae300e-b66f-4af6-beff-0cde9f0cc09e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e09015d1abe44c3af915222c21fc05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hint_matrix = build_hint_matrix(vocab_list=vocab_list, save=\"data/hint_matrix.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adfa7b3-6c88-4a37-84dc-78609b66c38f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculating Word Entropy\n",
    "\n",
    "Each potential guess word is associated with a distribution of possible hints (assuming that we select a goal word uniformly at random). The simplest approach is to assign an entropy value to each guess word according to its hint distribution. A more sophisticated approach takes into account the distribution of entropies conditioned on each possible hint that could be recieved after guessing. We can perform this evaluation recursively in order to determine the expected entropy of a set of word choices rather than a single choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d194b7d8-6ea5-466a-a1f3-2bf46cb71935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_entropy(word_idxs, entropies):\n",
    "    sorted_args = np.argsort(entropies)[::-1]\n",
    "    return word_idxs[sorted_args], entropies[sorted_args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "09f58515-637f-46b2-974e-c7a856194ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropies(hint_matrix, word_idxs=None, sort=False):\n",
    "    word_idxs = pd.unique(word_idxs) if word_idxs is not None else np.arange(hint_matrix.shape[0])\n",
    "    entropies = np.zeros_like(word_idxs, dtype=float)\n",
    "    for i in range(word_idxs.shape[0]):\n",
    "        word_idx = word_idxs[i]\n",
    "        hint_counts = np.bincount(hint_matrix[word_idx])\n",
    "        entropies[i] = entropy(hint_counts)\n",
    "    \n",
    "    if sort:\n",
    "        word_idxs, entropies = sort_by_entropy(word_idxs, entropies)\n",
    "\n",
    "    return word_idxs, entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a609aa7b-fc14-4070-a8f4-1517e7611765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.29339006, 4.26279884, 4.23813968, ..., 1.37084733, 1.30764523,\n",
       "       1.30384486])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idxs, entropies = get_entropies(hint_matrix, sort=True)\n",
    "entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "bee78ead-2887-49d4-add5-65fc951c9377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_word_entropies(word_idxs, entropies, cutoff=50):\n",
    "    word_idxs, entropies = sort_by_entropy(word_idxs, entropies)\n",
    "    print(f\" Word | Entropy\")\n",
    "    print(f\"------+---------\")\n",
    "    for i in range(min(cutoff, word_idxs.shape[0])):\n",
    "        word_idx = word_idxs[i]\n",
    "        word = vocab_list[word_idx]\n",
    "        entropy_val = entropies[i]\n",
    "        print(f\"{word} | {entropy_val:0.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5f8a81c9-6100-45fe-bc46-17ebd73dcf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Word | Entropy\n",
      "------+---------\n",
      "tares | 4.29339\n",
      "lares | 4.26280\n",
      "rales | 4.23814\n",
      "rates | 4.22559\n",
      "teras | 4.21199\n",
      "nares | 4.20521\n",
      "soare | 4.20144\n",
      "tales | 4.19700\n",
      "reais | 4.19339\n",
      "tears | 4.18130\n",
      "arles | 4.17944\n",
      "tores | 4.17156\n",
      "salet | 4.17056\n",
      "aeros | 4.16823\n",
      "dares | 4.16605\n",
      "saner | 4.15837\n",
      "reals | 4.15830\n",
      "lears | 4.15111\n",
      "lores | 4.14292\n",
      "serai | 4.14060\n",
      "lanes | 4.13899\n",
      "laers | 4.13739\n",
      "pares | 4.13625\n",
      "cares | 4.13560\n",
      "tires | 4.13349\n",
      "saine | 4.13299\n",
      "seral | 4.12672\n",
      "mares | 4.12546\n",
      "reans | 4.12479\n",
      "aloes | 4.12056\n",
      "sared | 4.11910\n",
      "roles | 4.11865\n",
      "teals | 4.11613\n",
      "aures | 4.11047\n",
      "earls | 4.10802\n",
      "taels | 4.10409\n",
      "raise | 4.10325\n",
      "tries | 4.10288\n",
      "rotes | 4.10152\n",
      "sorel | 4.10113\n",
      "leats | 4.09809\n",
      "nears | 4.09319\n",
      "toeas | 4.09305\n",
      "strae | 4.08800\n",
      "rones | 4.08691\n",
      "nates | 4.08649\n",
      "earns | 4.07899\n",
      "taser | 4.07798\n",
      "toles | 4.07752\n",
      "dales | 4.07735\n"
     ]
    }
   ],
   "source": [
    "display_word_entropies(word_idxs, entropies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507d6d4-01a1-4c13-a586-1345dfda8aad",
   "metadata": {},
   "source": [
    "### Recursive Entropy\n",
    "\n",
    "Although the unconditional entropy of each guess word is a good indicator for how it will perform, the unconditional entropy only evaluates how well a guess will narrow down the set of solution words. It is possible that an initial guess word with a high entropy will result in all second guess-words having a low entropy. Therefore, rather than maximizing the entropy of the initial guess word, it is even more optimal to evaluate the entropy of a series of guesses. The entropy of each successive guess is conditioned on the the previous guesses and the entropies are summed in order to get the joint entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c33bfd0e-2378-4a72-9a8b-181ac5247ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_recursive_max_entropies(hint_matrix, word_idxs=None, max_depth=None, curr_depth=0, hard_mode=True, progress_bar=False, sort=False):\n",
    "    word_idxs, entropies = get_entropies(hint_matrix, word_idxs) # these are the unconditional entropies of each word\n",
    "    n_guesses = word_idxs.shape[0]\n",
    "    n_solutions = hint_matrix.shape[1]\n",
    "    \n",
    "    if (max_depth is None) or (curr_depth < max_depth):\n",
    "        for i in tqdm_notebook(range(n_guesses)) if progress_bar else range(n_guesses):\n",
    "            word_idx = word_idxs[i]\n",
    "            hint_ids, hint_counts = np.unique(hint_matrix[curr_idx], return_counts=True)\n",
    "            hint_distribution = hint_counts / n_solutions\n",
    "            n_hints = hint_ids.shape[0]\n",
    "\n",
    "            max_entropies = np.zeros(n_hints, dtype=float)\n",
    "            for j in range(n_hints):\n",
    "                print(f\"\\r~~~~~~~~~~ Evaluating hint {j+1}/{n_hints} at depth {curr_depth+1}/{max_depth} ~~~~~~~~~~\", end=\"\")\n",
    "                hint_id = hint_ids[j] # assume that this is the hint received in response to our current guess word\n",
    "                viable_solutions = hint_matrix[i] == hint_id\n",
    "                next_matrix = hint_matrix[:, viable_solutions] # takes only the columns of the hint matrix with viable goal words\n",
    "                next_idxs = viable_solutions.nonzero()[0] if hard_mode else None\n",
    "                _, next_entropies = get_recursive_max_entropies(next_matrix, next_idxs, max_depth, curr_depth+1, hard_mode, sort=False)\n",
    "                max_entropies[j] = 0. if next_entropies.shape[0] == 0 else np.max(next_entropies)\n",
    "\n",
    "            entropies[i] += np.sum(max_entropies * hint_distribution)\n",
    "        \n",
    "    if sort:\n",
    "        word_idxs, entropies = sort_by_entropy(word_idxs, entropies)\n",
    "    \n",
    "    return idxs, entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7fe9f536-d014-4eac-8937-e3e20c9b944b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41360e37c014a7799bdb5b66b389102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~ Evaluating hint 189/189 at depth 1/1 ~~~~~~~~~~"
     ]
    }
   ],
   "source": [
    "word_idxs, deep_entropies = get_recursive_max_entropies(hint_matrix, idxs[:50], max_depth=1, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7712cd47-dfcc-460d-ac78-3f97d00bcb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Word | Entropy\n",
      "------+---------\n",
      "tares | 7.14560\n",
      "arles | 7.07825\n",
      "cares | 7.04644\n",
      "rones | 7.03413\n",
      "nares | 7.02628\n",
      "rates | 7.01536\n",
      "tores | 6.97134\n",
      "roles | 6.96526\n",
      "aures | 6.89405\n",
      "pares | 6.89024\n",
      "reans | 6.88279\n",
      "laers | 6.87883\n",
      "tries | 6.85827\n",
      "serai | 6.82277\n",
      "reais | 6.81978\n",
      "mares | 6.81436\n",
      "earns | 6.80884\n",
      "toles | 6.80737\n",
      "aeros | 6.77245\n",
      "tears | 6.73486\n",
      "reals | 6.72963\n",
      "taser | 6.72768\n",
      "lares | 6.72716\n",
      "leats | 6.70785\n",
      "rotes | 6.69841\n",
      "soare | 6.66942\n",
      "strae | 6.63430\n",
      "tales | 6.62036\n",
      "teals | 6.56793\n",
      "dales | 6.55376\n",
      "sorel | 6.51172\n",
      "salet | 6.49798\n",
      "rales | 6.25270\n",
      "saner | 6.21693\n",
      "lores | 6.16370\n",
      "saine | 6.15980\n",
      "dares | 6.15869\n",
      "lanes | 6.12102\n",
      "nates | 6.11480\n",
      "teras | 6.10602\n",
      "earls | 6.04947\n",
      "lears | 6.04854\n",
      "raise | 6.02050\n",
      "sared | 6.00368\n",
      "aloes | 5.96444\n",
      "toeas | 5.95614\n",
      "nears | 5.95606\n",
      "tires | 5.92112\n",
      "taels | 5.73873\n",
      "seral | 5.47017\n"
     ]
    }
   ],
   "source": [
    "display_word_entropies(word_idxs, deep_entropies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f149913-6a44-4ae8-97d2-b1c6a14d84ba",
   "metadata": {},
   "source": [
    "## WORDLE REPL\n",
    "\n",
    "To make a interacting with this code a little easier, we can create repl to run while solving the wordle. Since the recursive calculation of the joint entropies is slow we are only using the unconditional entropy of the initial guess word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3c6dfc15-20e5-4a40-ad00-619e5b030cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are best guess words\n",
      " Word | Entropy\n",
      "------+---------\n",
      "tares | 4.29339\n",
      "lares | 4.26280\n",
      "rales | 4.23814\n",
      "rates | 4.22559\n",
      "teras | 4.21199\n",
      "nares | 4.20521\n",
      "soare | 4.20144\n",
      "tales | 4.19700\n",
      "reais | 4.19339\n",
      "tears | 4.18130\n",
      "arles | 4.17944\n",
      "tores | 4.17156\n",
      "salet | 4.17056\n",
      "aeros | 4.16823\n",
      "dares | 4.16605\n",
      "saner | 4.15837\n",
      "reals | 4.15830\n",
      "lears | 4.15111\n",
      "lores | 4.14292\n",
      "serai | 4.14060\n",
      "lanes | 4.13899\n",
      "laers | 4.13739\n",
      "pares | 4.13625\n",
      "cares | 4.13560\n",
      "tires | 4.13349\n",
      "saine | 4.13299\n",
      "seral | 4.12672\n",
      "mares | 4.12546\n",
      "reans | 4.12479\n",
      "aloes | 4.12056\n",
      "sared | 4.11910\n",
      "roles | 4.11865\n",
      "teals | 4.11613\n",
      "aures | 4.11047\n",
      "earls | 4.10802\n",
      "taels | 4.10409\n",
      "raise | 4.10325\n",
      "tries | 4.10288\n",
      "rotes | 4.10152\n",
      "sorel | 4.10113\n",
      "leats | 4.09809\n",
      "nears | 4.09319\n",
      "toeas | 4.09305\n",
      "strae | 4.08800\n",
      "rones | 4.08691\n",
      "nates | 4.08649\n",
      "earns | 4.07899\n",
      "taser | 4.07798\n",
      "toles | 4.07752\n",
      "dales | 4.07735\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a guess word:  tares\n",
      "Enter the resulting hint:  __o__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here are best guess words\n",
      " Word | Entropy\n",
      "------+---------\n",
      "prion | 3.49912\n",
      "groin | 3.48511\n",
      "courd | 3.47519\n",
      "droil | 3.47314\n",
      "brond | 3.45564\n",
      "proin | 3.44882\n",
      "crony | 3.43502\n",
      "irony | 3.42428\n",
      "drony | 3.41796\n",
      "crudo | 3.41567\n",
      "bourn | 3.38581\n",
      "bruin | 3.38427\n",
      "bourd | 3.38278\n",
      "bronc | 3.37978\n",
      "gourd | 3.37555\n",
      "round | 3.37551\n",
      "orcin | 3.37178\n",
      "broil | 3.36792\n",
      "courb | 3.33285\n",
      "grind | 3.33058\n",
      "yourn | 3.32693\n",
      "mourn | 3.31706\n",
      "croon | 3.31577\n",
      "inorb | 3.31132\n",
      "proud | 3.29118\n",
      "proyn | 3.28680\n",
      "cronk | 3.28490\n",
      "frond | 3.27143\n",
      "drouk | 3.26881\n",
      "robin | 3.26861\n",
      "croup | 3.26851\n",
      "grund | 3.26735\n",
      "crown | 3.25389\n",
      "fiord | 3.25187\n",
      "bourg | 3.24513\n",
      "drown | 3.24240\n",
      "prong | 3.23812\n",
      "orpin | 3.23594\n",
      "guiro | 3.23369\n",
      "crowd | 3.23195\n",
      "grody | 3.23138\n",
      "briny | 3.22981\n",
      "bring | 3.20751\n",
      "drink | 3.20502\n",
      "crudy | 3.20220\n",
      "proul | 3.19420\n",
      "drily | 3.19264\n",
      "cromb | 3.18792\n",
      "chord | 3.18696\n",
      "brood | 3.18642\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a guess word:  prion\n",
      "Enter the resulting hint:  _o___\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here are best guess words\n",
      " Word | Entropy\n",
      "------+---------\n",
      "blurb | 2.09473\n",
      "rhumb | 1.97920\n",
      "flurr | 1.81431\n",
      "rugby | 1.74816\n",
      "churl | 1.69878\n",
      "rumly | 1.63263\n",
      "churr | 1.58903\n",
      "rubby | 1.56071\n",
      "uhuru | 1.35798\n",
      "ruggy | 1.35221\n",
      "rummy | 1.35221\n",
      "ruddy | 1.14371\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a guess word:  rhumb\n",
      "Enter the resulting hint:  o_x_x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The goal word is \"blurb\"\n"
     ]
    }
   ],
   "source": [
    "GOAL_WORD = None\n",
    "HARD_MODE = True\n",
    "\n",
    "state = \"suggesting\"\n",
    "hint_matrix_cpy = hint_matrix.copy()\n",
    "remaining_words = np.arange(hint_matrix_cpy.shape[1])\n",
    "while True:\n",
    "    if state == \"guessing\":\n",
    "        guess = input(\"Enter a guess word: \")\n",
    "        while True:\n",
    "            if guess not in vocab_to_idx:\n",
    "                print(f\"\\\"{guess}\\\" is not in the vocab list, try another word\")\n",
    "                guess = input(\"Enter a new guess word: \")\n",
    "            elif HARD_MODE and vocab_to_idx[guess] not in remaining_words:\n",
    "                print(f\"\\\"{guess}\\\" is not a viable guess in hard-mode\")\n",
    "                guess = input(\"Enter a new guess word: \")\n",
    "            else:\n",
    "                break\n",
    "        guess_idx = vocab_to_idx[guess]\n",
    "        state = \"hinting\"\n",
    "    \n",
    "    if state == \"hinting\":\n",
    "        if GOAL_WORD is None:\n",
    "            hint_str = input(\"Enter the resulting hint: \")    \n",
    "            hint = str_to_hint(hint_str)\n",
    "        else:\n",
    "            hint = get_hint(guess, GOAL_WORD)\n",
    "            print(f\"The hint is \\\"{hint_to_str(hint)}\\\"\")\n",
    "        hint_num = hint_to_num(hint)\n",
    "        valid_words = hint_matrix_cpy[guess_idx] == hint_num\n",
    "        remaining_words = remaining_words[valid_words]\n",
    "        hint_matrix_cpy = hint_matrix_cpy[:, valid_words]\n",
    "        state = \"suggesting\"\n",
    "        print()\n",
    "    \n",
    "    if state == \"suggesting\":\n",
    "        word_idxs = remaining_words if HARD_MODE else None\n",
    "        word_idxs, entropies = get_entropies(hint_matrix_cpy, word_idxs)\n",
    "        if remaining_words.shape[0] == 0:\n",
    "            print(\"There are no more possible words in this vocab list\")\n",
    "            break\n",
    "        if remaining_words.shape[0] == 1:\n",
    "            remaining_word = vocab_list[remaining_words[0]]\n",
    "            print(f\"The goal word is \\\"{remaining_word}\\\"\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Here are the best guess words\")\n",
    "            display_word_entropies(word_idxs, entropies)\n",
    "            print()\n",
    "        state = \"guessing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab241794-862f-4b66-9c95-3949f64fc485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
